{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"04_Normalisation.ipynb","provenance":[{"file_id":"12XP_WZ0yozRtpkmILZ8lJg8LYKx5jRbt","timestamp":1595236012729}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"view-in-github","colab_type":"text"},"source":["<a href=\"https://colab.research.google.com/github/davidcpage/mctc/blob/master/notebooks/01_CTC_loss.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"code","metadata":{"id":"5eu0cLH33Q09","colab_type":"code","colab":{}},"source":["# default_exp normalisation"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lwSCvHH9S_TO","colab_type":"text"},"source":["# Normalisation\n","\n","> Partition function calculations."]},{"cell_type":"code","metadata":{"id":"3Rsd7qFH3rK7","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595493995767,"user_tz":-60,"elapsed":7232,"user":{"displayName":"david page","photoUrl":"","userId":"15385526310632231424"}}},"source":["#export\n","import numpy as np\n","import cupy as cp\n","import torch\n","from mctc.utils import *\n","\n","device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IfMZxoqjAzUd","colab_type":"text"},"source":["\n","## Preliminaries"]},{"cell_type":"markdown","metadata":{"id":"f5QhUc8ErIKK","colab_type":"text"},"source":["Generate a test example:"]},{"cell_type":"code","metadata":{"id":"MCZLaJdsgioY","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595493995769,"user_tz":-60,"elapsed":1524,"user":{"displayName":"david page","photoUrl":"","userId":"15385526310632231424"}}},"source":["#export\n","def generate_test_example(T, N, n_state, dtype=torch.float):\n","    return torch.rand((T, N, n_state, n_state), device=device, dtype=dtype, requires_grad=True)"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FmZa5QcOcEzC","colab_type":"text"},"source":["### 1. Basic pytorch"]},{"cell_type":"code","metadata":{"id":"IUvG4fxH0vHB","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595494004165,"user_tz":-60,"elapsed":9202,"user":{"displayName":"david page","photoUrl":"","userId":"15385526310632231424"}}},"source":["T = 4032//5\n","N = 128\n","n_state = 8\n","Ms = generate_test_example(T, N, n_state)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"02W6FYF-9zDL","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595494004165,"user_tz":-60,"elapsed":7904,"user":{"displayName":"david page","photoUrl":"","userId":"15385526310632231424"}}},"source":["#export\n","import torch\n","\n","def _rescale(M):\n","    #T, N, n_state, n_state = M.shape\n","    Z = M.sum((2, 3), keepdim=True) / M.size(3)\n","    logZ = torch.log(Z).sum(0).reshape(-1)\n","    return M / Z, logZ    \n","\n","@torch.jit.script\n","def logZ_py(M, alpha_0):\n","    M, logZ = _rescale(M)\n","    T, N, n_state, _ = M.shape\n","    alpha = alpha_0.unsqueeze(2)\n","    for i, M_t in enumerate(M.unbind(0)):\n","        alpha = M_t.bmm(alpha)\n","        if i % 32 == (T - 1) % 32:\n","            z = alpha.sum(1, keepdim=True)\n","            alpha = alpha/z\n","            logZ += torch.log(z.squeeze())\n","    return logZ"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"9IsVKnjp4R4C","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595494004166,"user_tz":-60,"elapsed":7670,"user":{"displayName":"david page","photoUrl":"","userId":"15385526310632231424"}}},"source":["#report(benchmark_fwd_bwd((lambda M, alpha_0: logZ_fwd(M, alpha_0).mean()), M, alpha_0))"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"a7ZLRSjCoG6i","colab_type":"text"},"source":["### 3. Cupy"]},{"cell_type":"code","metadata":{"id":"fzyYeFSfFPWU","colab_type":"code","colab":{}},"source":["%%writefile cuda/fused_bmv.cu\n","__device__ __forceinline__ FLOAT max2(FLOAT a, FLOAT a1) {\n","    return a > a1 ? a : a1; \n","}\n","\n","__device__ __forceinline__ FLOAT logsumexp2(FLOAT a, FLOAT a1) {\n","    FLOAT maxa = max2(a, a1); \n","    return maxa + log(exp(a-maxa) + exp(a1-maxa));\n","}\n","\n","__device__ __forceinline__ FLOAT add(FLOAT a, FLOAT b) {return a + b;}\n","__device__ __forceinline__ FLOAT mul(FLOAT a, FLOAT b) {return a * b;}\n","\n","extern \"C\" __global__ void fwd(\n","    FLOAT* __restrict__ alpha,\n","    const FLOAT* __restrict__ Ms, \n","    int T, int N, int n_state\n",") {\n","    // Ms is shape (T, N, n_state, n_state)\n","    // alpha is shape (T + 1, N, n_state)\n","    // assumes blockDim = (N, 1, 1) and threadDim = (n_state, 1, 1)\n","\n","    int bx = blockIdx.x, tx = threadIdx.x;\n","    if (tx >= n_state) return;\n","    FLOAT u;\n","    for (int t = 0; t < T; t++) {\n","        int j = (t * N + bx) * n_state;\n","        u = MUL(Ms[(j + tx) * n_state], alpha[j]);\n","        for (int i = 1; i < n_state; i++) {\n","            u = SUM(u, MUL(Ms[(j + tx) * n_state + i], alpha[j + i]));\n","        }\n","        alpha[j + (N * n_state) + tx] = u;\n","        __syncthreads();\n","    }\n","  }"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KJw4HISCmPDH","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595494741955,"user_tz":-60,"elapsed":481,"user":{"displayName":"david page","photoUrl":"","userId":"15385526310632231424"}}},"source":["#export\n","from mctc.ctc import semiring, Log, Max\n","from functools import partial\n","\n","cupy_funcs = {\n","    (torch.float32, Log): load_cupy_func('cuda/fused_bmv.cu', 'fwd', FLOAT='float', MUL='add', SUM='logsumexp2'),\n","    (torch.float64, Log): load_cupy_func('cuda/fused_bmv.cu', 'fwd', FLOAT='double', MUL='add', SUM='logsumexp2'),\n","    (torch.float32, Max): load_cupy_func('cuda/fused_bmv.cu', 'fwd', FLOAT='float',  MUL='add', SUM='max2'),\n","    (torch.float64, Max): load_cupy_func('cuda/fused_bmv.cu', 'fwd', FLOAT='double', MUL='add', SUM='max2'),\n","}\n","\n","def fused_batch_Mv(Ms, alpha_0, S:semiring=Log):\n","    T, N, n_state, _ = Ms.shape\n","    alpha = Ms.new_empty((T + 1, N, n_state))\n","    alpha[0] = alpha_0\n","    with cp.cuda.Device(Ms.device.index):\n","        cupy_funcs[(Ms.dtype, S)](\n","            grid=(N, 1, 1), \n","            block=(n_state, 1, 1), \n","            args=(alpha.data_ptr(), Ms.contiguous().data_ptr(), T, N, n_state)\n","        )\n","    return alpha\n","\n","def _logz_fwd(ctx, Ms, alpha_0, beta_T, S:semiring=Log):\n","    alpha = fused_batch_Mv(Ms, alpha_0, S)\n","    ctx.save_for_backward(Ms, alpha, beta_T)\n","    return S.sum(S.mul(alpha[-1], beta_T), dim=1)    \n","\n","def _logz_bwd(ctx, g, S:semiring=Log):\n","    Ms, alpha, beta_T = ctx.saved_tensors\n","    T, N, n_state, _ = Ms.shape\n","    beta = fused_batch_Mv(Ms.transpose(2, 3).flip(0), beta_T)\n","    Ms_grad = S.mul(S.mul(Ms, alpha[:-1,:,None,:]), (beta[:-1, :, :, None]).flip(0))\n","    Ms_grad = S.dsum(Ms_grad.reshape(T, N, -1), dim=2).reshape(T, N, n_state, n_state)\n","    return Ms_grad * g[None, :, None, None], None, None, None \n","\n","class LogZ(torch.autograd.Function):\n","    forward = staticmethod(_logz_fwd)\n","    backward = staticmethod(_logz_bwd)\n","\n","class LogZViterbi(torch.autograd.Function):\n","    forward = staticmethod(partial(_logz_fwd, S=Max))\n","    backward = staticmethod(partial(_logz_bwd, S=Max))\n","\n","def logz(Ms, alpha_0, beta_T, S:semiring=Log):\n","    if S==Log:\n","        return LogZ.apply(Ms, alpha_0, beta_T)\n","    elif S==Max:\n","        return LogZViterbi.apply(Ms, alpha_0, beta_T)\n","    else: \n","        raise Exception('semiring {} not supported'.format(S))"],"execution_count":43,"outputs":[]}]}