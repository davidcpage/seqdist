{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"05_Sparse.ipynb","provenance":[{"file_id":"1N-VzMMZcVlPxPfVxC5bbgKJXQ-B2q4zw","timestamp":1597311240394},{"file_id":"12XP_WZ0yozRtpkmILZ8lJg8LYKx5jRbt","timestamp":1595236012729}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"view-in-github","colab_type":"text"},"source":["<a href=\"https://colab.research.google.com/github/davidcpage/mctc/blob/master/notebooks/01_CTC_loss.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"code","metadata":{"id":"5eu0cLH33Q09","colab_type":"code","colab":{}},"source":["# default_exp sparse"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lwSCvHH9S_TO","colab_type":"text"},"source":["# Sparse\n","\n","> Sparse partition function calculations."]},{"cell_type":"code","metadata":{"id":"3Rsd7qFH3rK7","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597596159375,"user_tz":-60,"elapsed":1536,"user":{"displayName":"david page","photoUrl":"","userId":"15385526310632231424"}}},"source":["#export\n","from functools import partial, lru_cache as cache\n","import numpy as np\n","import cupy as cp\n","import torch\n","from mctc.utils import *\n","from mctc.ctc import semiring, Max, Log, interleave_blanks, generate_sample_inputs, loss_pytorch, benchmark_fwd_bwd, report, compare_fwd_bwd\n","\n","device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FmZa5QcOcEzC","colab_type":"text"},"source":["### 1. Basic pytorch"]},{"cell_type":"code","metadata":{"id":"bYeJsJjvNJKf","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597596164358,"user_tz":-60,"elapsed":878,"user":{"displayName":"david page","photoUrl":"","userId":"15385526310632231424"}}},"source":["#export\n","def Mv_scan_py(Ms, idx, v0, S:semiring=Log):\n","    T, N, C, nz = Ms.shape\n","    alpha = Ms.new_full((T+1, N, C), S.zero)\n","    alpha[0] = v0 \n","    for t in range(T):\n","        alpha[t+1] = S.sum(S.mul(Ms[t], alpha[t, :, idx]), dim=2)\n","    return alpha\n","\n","def transpose(Ms, idx):\n","    T, N, C, nz = Ms.shape\n","    assert idx.shape == (C, nz) \n","    i = idx.flatten().argsort().reshape(C, nz)\n","    idx_T = i // nz\n","    Ms_T = Ms.reshape(T, N, -1)[:, :, i]\n","    return Ms_T, idx_T\n","\n","class _LogZ_scan(torch.autograd.Function):\n","    @staticmethod\n","    def forward(ctx, Ms, idx, v0, vT, S:semiring, scan):\n","        alpha = scan(Ms, idx, v0, S)\n","        ctx.save_for_backward(alpha, Ms, idx, vT)\n","        ctx.semiring, ctx.scan = S, scan\n","        return S.sum(S.mul(alpha[-1], vT), dim=1)\n","    \n","    @staticmethod\n","    def backward(ctx, grad):\n","        alpha, Ms, idx, vT = ctx.saved_tensors\n","        S, scan = ctx.semiring, ctx.scan\n","        T, N, C, nz = Ms.shape\n","        Ms_T, idx_T = transpose(Ms, idx)\n","        beta = scan(Ms_T.flip(0), idx_T, vT, S)\n","        g = S.mul(S.mul(Ms.reshape(T, N, -1), alpha[:-1, :, idx.flatten()]).reshape(T, N, C, nz), beta[:-1, :, :, None].flip(0))\n","        g = S.dsum(g.reshape(T, N, -1), dim=2).reshape(T, N, C, nz)\n","        return grad[None, :, None, None] * g, None, None, None, None, None \n","\n","def logZ_scan_py(Ms, idx, v0, vT, S:semiring):\n","    return _LogZ_scan.apply(Ms, idx, v0, vT, S, Mv_scan_py)"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8GMTC7KsPgbN","colab_type":"text"},"source":["### 2. CTC loss using sparse LogZ"]},{"cell_type":"markdown","metadata":{"id":"TACdU4DEPqEQ","colab_type":"text"},"source":["NB: This is only as a test/demo - it is slower than the previous CTC loss implementation and only supports the case where all input_lengths are equal to T (although this could be fixed.)"]},{"cell_type":"code","metadata":{"id":"EJUJcTwwOUd6","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597596168182,"user_tz":-60,"elapsed":662,"user":{"displayName":"david page","photoUrl":"","userId":"15385526310632231424"}}},"source":["#export\n","from torch.nn.functional import pad\n","\n","def _ctc_loss(logits, targets, input_lengths, target_lengths, logZ_impl, S:semiring=Log):\n","    zero, one = [logits.new_full((1,), x) for x in (S.zero, S.one)]\n","    scores = logits.log_softmax(2)\n","    states = interleave_blanks(targets, blank_idx=0)\n","    state_scores = torch.gather(scores, 2, states.expand(scores.size(0), -1, -1))\n","    final_states = torch.stack([target_lengths*2-1, target_lengths*2], 1)\n","\n","    T, N, Lp = state_scores.shape\n","    assert torch.all(input_lengths == T)\n","\n","    Ms = torch.stack([\n","        state_scores, \n","        pad(state_scores[:, :, 1:], (1, 0), value=S.zero),\n","        pad(torch.where(states[:, 2:] == states[:, :-2], zero.expand(T, N, Lp-2), state_scores[:, :, 2:]), (2, 0), value=S.zero)\n","    ], -1)\n","\n","    i = torch.arange(Lp, device=device)\n","    rot = lambda x, n: torch.cat([x[-n:], x[:-n]])\n","    idx = torch.stack([i, rot(i, 1), rot(i, 2)], dim=1)\n","\n","    v0 = torch.cat([one.expand(N, 1), zero.expand(N, Lp - 1)], dim=1)\n","    vT = zero.expand(N, Lp).clone().scatter_(1, final_states, S.one)\n","    \n","    logZ = logZ_impl(Ms, idx, v0, vT, S)\n","    return -(logZ / target_lengths).mean()\n","\n","ctc_loss_scan_py = partial(_ctc_loss, logZ_impl=logZ_scan_py)"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"MQ-2OXpkO4ad","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":50},"executionInfo":{"status":"ok","timestamp":1597596173119,"user_tz":-60,"elapsed":3385,"user":{"displayName":"david page","photoUrl":"","userId":"15385526310632231424"}},"outputId":"ef6fe97f-c2c8-4cc0-a7d7-0a8395d69ab1"},"source":["sample_inputs = logits, targets, input_lengths, target_lengths = generate_sample_inputs(T_min=500, T_max=500, N=128, C=20, L_min=80, L_max=100)\n","fwd, bwd = compare_fwd_bwd(loss_pytorch, ctc_loss_scan_py, *sample_inputs)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["fwd diff: 0.00e+00\n","bwd diff: 1.09e-07\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"a7ZLRSjCoG6i","colab_type":"text"},"source":["### 3. Cupy"]},{"cell_type":"code","metadata":{"id":"fzyYeFSfFPWU","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1597596184131,"user_tz":-60,"elapsed":1042,"user":{"displayName":"david page","photoUrl":"","userId":"15385526310632231424"}},"outputId":"027d4aed-3514-47a7-8141-ff63726c6e49"},"source":["%%writefile cuda/sparse_scan.cu\n","__device__ __forceinline__ FLOAT max2(FLOAT a, FLOAT b) {return a > b ? a : b;}\n","__device__ __forceinline__ FLOAT logsumexp2(FLOAT a, FLOAT b) {return a > b ? log1p(exp(b - a)) + a : log1p(exp(a - b)) + b;}\n","__device__ __forceinline__ FLOAT add(FLOAT a, FLOAT b) {return a + b;}\n","\n","extern \"C\" __global__ void sparse_Mv_scan(\n","    FLOAT* __restrict__ alpha,\n","    const FLOAT* __restrict__ Ms,  \n","    const int* __restrict__ idx,\n","    int T, int N, int C, int nz\n",") {\n","    int bx = blockIdx.x, tx = threadIdx.x;\n","    if (tx >= C) return;\n","    extern __shared__ FLOAT smem[];\n","    \n","    FLOAT a = alpha[bx * C + tx];\n","    for (int t = 0; t < T; t++) {\n","        FLOAT *buf = smem + (t % 2) * blockDim.x;\n","        buf[tx] = a; __syncthreads();      \n","        int i = ((t * N + bx) * C) + tx;\n","        a = MUL(buf[idx[tx * nz]], Ms[i * nz]);\n","        for (int j = 1; j < nz; j++) {\n","            a = ADD(a, MUL(buf[idx[tx * nz + j]], Ms[i * nz + j]));\n","        }\n","        alpha[i + N * C] = a;\n","    }\n","}"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Overwriting mctc/cuda/sparse_scan.cu\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qXMMQ-9WQbyZ","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597596198206,"user_tz":-60,"elapsed":443,"user":{"displayName":"david page","photoUrl":"","userId":"15385526310632231424"}}},"source":["#export\n","cupy_funcs = {\n","    (torch.float32, Log): load_cupy_func('cuda/sparse_scan.cu', 'sparse_Mv_scan', FLOAT='float',  ADD='logsumexp2', MUL='add', ZERO='{:E}'.format(Log.zero)),\n","    (torch.float64, Log): load_cupy_func('cuda/sparse_scan.cu', 'sparse_Mv_scan', FLOAT='double',  ADD='logsumexp2', MUL='add', ZERO='{:E}'.format(Log.zero)),\n","    (torch.float32, Max): load_cupy_func('cuda/sparse_scan.cu', 'sparse_Mv_scan', FLOAT='float',  ADD='max2', MUL='add', ZERO='{:E}'.format(Log.zero)),\n","    (torch.float64, Max): load_cupy_func('cuda/sparse_scan.cu', 'sparse_Mv_scan', FLOAT='double',  ADD='max2', MUL='add', ZERO='{:E}'.format(Log.zero)),\n","}\n","\n","def Mv_scan_cupy(Ms, idx, v0, S:semiring):\n","    T, N, C, nz = Ms.shape\n","    assert idx.shape == (C, nz) \n","    alpha = Ms.new_full((T+1, N, C), S.zero)\n","    alpha[0] = v0\n","    with cp.cuda.Device(Ms.device.index):\n","        cupy_funcs[(Ms.dtype, S)](grid=(N, 1, 1), block=(C, 1, 1), shared_mem=2*8*C,\n","               args=(alpha.data_ptr(), Ms.data_ptr(), idx.to(dtype=torch.int, device=Ms.device).data_ptr(), T, N, C, nz))\n","    return alpha\n","\n","def logZ_scan(Ms, idx, v0, vT, S:semiring):\n","    return _LogZ_scan.apply(Ms, idx, v0, vT, S, Mv_scan_cupy)\n","\n","ctc_loss_scan = partial(_ctc_loss, logZ_impl=logZ_scan)"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"buhZaRPlQ_bW","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":50},"executionInfo":{"status":"ok","timestamp":1597596199937,"user_tz":-60,"elapsed":882,"user":{"displayName":"david page","photoUrl":"","userId":"15385526310632231424"}},"outputId":"dbad8a26-f0a8-416e-d245-6b12ef345c06"},"source":["sample_inputs = logits, targets, input_lengths, target_lengths = generate_sample_inputs(T_min=500, T_max=500, N=128, C=20, L_min=80, L_max=100)\n","fwd, bwd = compare_fwd_bwd(loss_pytorch, ctc_loss_scan, *sample_inputs)"],"execution_count":15,"outputs":[{"output_type":"stream","text":["fwd diff: 0.00e+00\n","bwd diff: 1.10e-07\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PybecCFhRZ0R","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":67},"executionInfo":{"status":"ok","timestamp":1597596202194,"user_tz":-60,"elapsed":921,"user":{"displayName":"david page","photoUrl":"","userId":"15385526310632231424"}},"outputId":"2af14814-b434-4af7-f42c-247e364d6aa9"},"source":["report(benchmark_fwd_bwd(loss_pytorch, *sample_inputs))"],"execution_count":16,"outputs":[{"output_type":"stream","text":["fwd: 3.58ms (3.13-4.03ms)\n","bwd: 8.33ms (8.03-8.93ms)\n","tot: 11.90ms (11.20-12.81ms)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tbhWco7jRVx-","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":67},"executionInfo":{"status":"ok","timestamp":1597596308590,"user_tz":-60,"elapsed":2530,"user":{"displayName":"david page","photoUrl":"","userId":"15385526310632231424"}},"outputId":"1e707fc9-7c6d-4578-c305-8db8f49645a1"},"source":["report(benchmark_fwd_bwd(ctc_loss_scan, *sample_inputs))"],"execution_count":27,"outputs":[{"output_type":"stream","text":["fwd: 16.84ms (16.23-19.04ms)\n","bwd: 41.01ms (39.50-47.61ms)\n","tot: 57.84ms (55.77-66.65ms)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"vEBXcfNJGHDP","colab_type":"text"},"source":["## 4. Faster grads in Cupy"]},{"cell_type":"code","metadata":{"id":"obRbaOHqF2fR","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1597596644566,"user_tz":-60,"elapsed":1143,"user":{"displayName":"david page","photoUrl":"","userId":"15385526310632231424"}},"outputId":"984cb3df-c43a-4afa-9743-bd079789e7cf"},"source":["%%writefile cuda/sparse_logZ.cu\n","__device__ __forceinline__ FLOAT max2(FLOAT a, FLOAT b) {return a > b ? a : b;}\n","__device__ __forceinline__ FLOAT logsumexp2(FLOAT a, FLOAT b) {return a > b ? log1p(exp(b - a)) + a : log1p(exp(a - b)) + b;}\n","__device__ __forceinline__ FLOAT add(FLOAT a, FLOAT b) {return a + b;}\n","\n","extern \"C\" __global__ void logZ_fwd_bwd(\n","    FLOAT* __restrict__ logZ,\n","    FLOAT* __restrict__ Ms_grad,\n","    const FLOAT* __restrict__ Ms,\n","    const FLOAT* __restrict__ Ms_T,\n","    const FLOAT* __restrict__ v0,\n","    const FLOAT* __restrict__ vT,\n","    const int* __restrict__ idx,\n","    const int* __restrict__ idx_T,\n","    int T, int N, int C\n",") {\n","    int bx = blockIdx.x, tx = threadIdx.x;\n","    if (tx >= C) return;\n","    extern __shared__ FLOAT smem[];\n","    \n","    FLOAT a = v0[bx * C + tx];\n","    FLOAT tmp;\n","    for (int t = 0; t < T; t++) {\n","        FLOAT *buf = smem + (t % 2) * blockDim.x;\n","        buf[tx] = a; __syncthreads();      \n","        int i = (((t * N + bx) * C) + tx) * NZ;\n","        a = MUL(buf[idx[tx * NZ]], Ms[i]);\n","        Ms_grad[i] = a;\n","        for (int j = 1; j < NZ; j++) {\n","            tmp = MUL(buf[idx[tx * NZ + j]], Ms[i + j]);\n","            Ms_grad[i + j] = tmp;\n","            a = ADD(a, tmp);\n","        }\n","    }\n","\n","    FLOAT b = vT[bx * C + tx];\n","    logZ[bx * C + tx] = MUL(a, b);\n","    __syncthreads();\n","\n","    for (int t = T - 1; t >= 0; t--) {\n","        FLOAT *buf = smem + (t % 2) * blockDim.x;\n","        buf[tx] = b; __syncthreads(); \n","        int i = (((t * N + bx) * C) + tx) * NZ;\n","        for (int j = 0; j < NZ; j++) {\n","            Ms_grad[i + j] = MUL(Ms_grad[i + j], b);\n","        }\n","        b = MUL(buf[idx_T[tx * NZ]], Ms_T[i]);\n","        for (int j = 1; j < NZ; j++) {\n","            b = ADD(b, MUL(buf[idx_T[tx * NZ + j]], Ms_T[i + j]));\n","        }\n","    }\n","}"],"execution_count":32,"outputs":[{"output_type":"stream","text":["Overwriting mctc/cuda/sparse_logZ.cu\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Ynyz6fzaF3YC","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597596648561,"user_tz":-60,"elapsed":620,"user":{"displayName":"david page","photoUrl":"","userId":"15385526310632231424"}}},"source":["#export\n","@cache(None)\n","def cupy_func(dtype, S, nz):\n","    float_types = {torch.float32: 'float', torch.float64: 'double'}\n","    ops = {\n","        Log: {'add': 'logsumexp2', 'mul': 'add'},\n","        Max: {'add': 'max2', 'mul': 'add'},    \n","    }\n","    return load_cupy_func('cuda/sparse_logZ.cu', 'logZ_fwd_bwd', FLOAT=float_types[dtype],  ADD=ops[S]['add'], MUL=ops[S]['mul'], ZERO='{:E}'.format(S.zero), NZ=nz)\n","\n","def _logZ_fwd_bwd_cupy(Ms, idx, v0, vT, S:semiring=Log):\n","    assert Ms.device.index is not None\n","    T, N, C, nz = Ms.shape\n","    assert idx.shape == (C, nz)\n","    idx = idx.to(dtype=torch.int, device=Ms.device)\n","    Ms_grad = Ms.new_full((T, N, C, nz), S.zero)\n","    logZ = Ms.new_full((N, C), S.zero)\n","    Ms_T, idx_T = transpose(Ms, idx)\n","    idx_T = idx_T.to(torch.int)\n","    with cp.cuda.Device(Ms.device.index):\n","        cupy_func(Ms.dtype, S, nz)(grid=(N, 1, 1), block=(C, 1, 1), shared_mem=2*8*C,\n","               args=(logZ.data_ptr(), Ms_grad.data_ptr(), Ms.data_ptr(), Ms_T.data_ptr(), v0.data_ptr(), vT.data_ptr(), idx.data_ptr(), idx_T.data_ptr(), T, N, C))\n","    return S.sum(logZ, dim=1), Ms_grad\n","\n","class _LogZ(torch.autograd.Function):\n","    @staticmethod\n","    def forward(ctx, Ms, idx, v0, vT, S:semiring):\n","        logZ, Ms_grad = _logZ_fwd_bwd_cupy(Ms, idx, v0, vT, S)\n","        ctx.save_for_backward(Ms_grad)\n","        ctx.semiring = S\n","        return logZ\n","    \n","    @staticmethod\n","    def backward(ctx, grad):\n","        Ms_grad, = ctx.saved_tensors\n","        T, N, C, nz = Ms_grad.shape\n","        Ms_grad = ctx.semiring.dsum(Ms_grad.reshape(T, N, -1), dim=2).reshape(T, N, C, nz)\n","        return grad[None, :, None, None] * Ms_grad, None, None, None, None\n","\n","def logZ(Ms, idx, v0, vT, S:semiring=Log):\n","    return _LogZ.apply(Ms, idx, v0, vT, S)\n","\n","ctc_loss = partial(_ctc_loss, logZ_impl=logZ)"],"execution_count":33,"outputs":[]},{"cell_type":"code","metadata":{"id":"wowTruRxHPOz","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":50},"executionInfo":{"status":"ok","timestamp":1597596650606,"user_tz":-60,"elapsed":935,"user":{"displayName":"david page","photoUrl":"","userId":"15385526310632231424"}},"outputId":"95283ea8-0de9-444b-928e-a3025fb9185e"},"source":["sample_inputs = logits, targets, input_lengths, target_lengths = generate_sample_inputs(T_min=500, T_max=500, N=128, C=20, L_min=80, L_max=100)\n","fwd, bwd = compare_fwd_bwd(loss_pytorch, ctc_loss, *sample_inputs)"],"execution_count":34,"outputs":[{"output_type":"stream","text":["fwd diff: 0.00e+00\n","bwd diff: 1.20e-07\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mHR_uQs1JW_2","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":67},"executionInfo":{"status":"ok","timestamp":1597596652449,"user_tz":-60,"elapsed":1456,"user":{"displayName":"david page","photoUrl":"","userId":"15385526310632231424"}},"outputId":"ebdb2d6a-14ca-482f-ba12-5895a0b8b99c"},"source":["report(benchmark_fwd_bwd(loss_pytorch, *sample_inputs))"],"execution_count":35,"outputs":[{"output_type":"stream","text":["fwd: 4.96ms (4.30-5.66ms)\n","bwd: 10.66ms (9.38-12.63ms)\n","tot: 15.62ms (13.95-18.17ms)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"iUkc9Hk7Jfx_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":67},"executionInfo":{"status":"ok","timestamp":1597596655624,"user_tz":-60,"elapsed":2835,"user":{"displayName":"david page","photoUrl":"","userId":"15385526310632231424"}},"outputId":"f0d3db6c-5915-4e51-d58e-72167ea3e93c"},"source":["report(benchmark_fwd_bwd(ctc_loss, *sample_inputs))"],"execution_count":36,"outputs":[{"output_type":"stream","text":["fwd: 25.55ms (25.02-26.68ms)\n","bwd: 20.65ms (20.47-21.58ms)\n","tot: 46.20ms (45.50-48.26ms)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0Ef1DjoeJhgp","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}