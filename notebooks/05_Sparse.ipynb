{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"05_Sparse.ipynb","provenance":[{"file_id":"1N-VzMMZcVlPxPfVxC5bbgKJXQ-B2q4zw","timestamp":1597311240394},{"file_id":"12XP_WZ0yozRtpkmILZ8lJg8LYKx5jRbt","timestamp":1595236012729}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"view-in-github","colab_type":"text"},"source":["<a href=\"https://colab.research.google.com/github/davidcpage/mctc/blob/master/notebooks/01_CTC_loss.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"code","metadata":{"id":"5eu0cLH33Q09","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597311271890,"user_tz":-60,"elapsed":713,"user":{"displayName":"david page","photoUrl":"","userId":"15385526310632231424"}}},"source":["# default_exp sparse"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lwSCvHH9S_TO","colab_type":"text"},"source":["# Sparse\n","\n","> Sparse partition function calculations."]},{"cell_type":"code","metadata":{"id":"3Rsd7qFH3rK7","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597312350999,"user_tz":-60,"elapsed":658,"user":{"displayName":"david page","photoUrl":"","userId":"15385526310632231424"}}},"source":["#export\n","from functools import partial\n","import numpy as np\n","import cupy as cp\n","import torch\n","from mctc.utils import *\n","from mctc.ctc import semiring, Max, Log, interleave_blanks, generate_sample_inputs, loss_pytorch, benchmark_fwd_bwd, report, compare_fwd_bwd\n","\n","device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"],"execution_count":17,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FmZa5QcOcEzC","colab_type":"text"},"source":["### 1. Basic pytorch"]},{"cell_type":"code","metadata":{"id":"bYeJsJjvNJKf","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597312408268,"user_tz":-60,"elapsed":330,"user":{"displayName":"david page","photoUrl":"","userId":"15385526310632231424"}}},"source":["#export\n","def Mv_scan_py(Ms, idx, v0, S:semiring=Log):\n","    T, N, C, nz = Ms.shape\n","    alpha = Ms.new_full((T+1, N, C), S.zero)\n","    alpha[0] = v0 \n","    for t in range(T):\n","        alpha[t+1] = S.sum(S.mul(Ms[t], alpha[t, :, idx]), dim=2)\n","    return alpha\n","\n","def transpose(Ms, idx):\n","    T, N, C, nz = Ms.shape\n","    assert idx.shape == (C, nz) \n","    i = idx.flatten().argsort().reshape(C, nz)\n","    idx_T = i // nz\n","    Ms_T = Ms.reshape(T, N, -1)[:, :, i]\n","    return Ms_T, idx_T\n","\n","class _LogZ(torch.autograd.Function):\n","    @staticmethod\n","    def forward(ctx, Ms, idx, v0, vT, S:semiring, scan):\n","        alpha = scan(Ms, idx, v0, S)\n","        ctx.save_for_backward(alpha, Ms, idx, vT)\n","        ctx.semiring, ctx.scan = S, scan\n","        return S.sum(S.mul(alpha[-1], vT), dim=1)\n","    \n","    @staticmethod\n","    def backward(ctx, grad):\n","        alpha, Ms, idx, vT = ctx.saved_tensors\n","        S, scan = ctx.semiring, ctx.scan\n","        T, N, C, nz = Ms.shape\n","        Ms_T, idx_T = transpose(Ms, idx)\n","        beta = scan(Ms_T.flip(0), idx_T, vT, S)\n","        g = S.mul(S.mul(Ms.reshape(T, N, -1), alpha[:-1, :, idx.flatten()]).reshape(T, N, C, nz), beta[:-1, :, :, None].flip(0))\n","        g = S.dsum(g.reshape(T, N, -1), dim=2).reshape(T, N, C, nz)\n","        return grad[None, :, None, None] * g, None, None, None, None, None \n","\n","logZ_py = partial(_LogZ.apply, S=Log, scan=Mv_scan_py)"],"execution_count":19,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8GMTC7KsPgbN","colab_type":"text"},"source":["### 2. CTC loss using sparse LogZ"]},{"cell_type":"markdown","metadata":{"id":"TACdU4DEPqEQ","colab_type":"text"},"source":["NB: This is only as a test/demo - it is slower than the previous CTC loss implementation and only supports the case where all input_lengths are equal to T (although this could be fixed.)"]},{"cell_type":"code","metadata":{"id":"EJUJcTwwOUd6","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597312632895,"user_tz":-60,"elapsed":654,"user":{"displayName":"david page","photoUrl":"","userId":"15385526310632231424"}}},"source":["#export\n","from torch.nn.functional import pad\n","\n","def _ctc_loss(logits, targets, input_lengths, target_lengths, scan, S:semiring=Log):\n","    zero, one = [logits.new_full((1,), x) for x in (S.zero, S.one)]\n","    scores = logits.log_softmax(2)\n","    states = interleave_blanks(targets, blank_idx=0)\n","    state_scores = torch.gather(scores, 2, states.expand(scores.size(0), -1, -1))\n","    final_states = torch.stack([target_lengths*2-1, target_lengths*2], 1)\n","\n","    T, N, Lp = state_scores.shape\n","    assert torch.all(input_lengths == T)\n","\n","    Ms = torch.stack([\n","        state_scores, \n","        pad(state_scores[:, :, 1:], (1, 0), value=S.zero),\n","        pad(torch.where(states[:, 2:] == states[:, :-2], zero.expand(T, N, Lp-2), state_scores[:, :, 2:]), (2, 0), value=S.zero)\n","    ], -1)\n","\n","    i = torch.arange(Lp, device=device)\n","    rot = lambda x, n: torch.cat([x[-n:], x[:-n]])\n","    idx = torch.stack([i, rot(i, 1), rot(i, 2)], dim=1)\n","\n","    v0 = torch.cat([one.expand(N, 1), zero.expand(N, Lp - 1)], dim=1)\n","    vT = zero.expand(N, Lp).clone().scatter_(1, final_states, S.one)\n","    \n","    logZ = _LogZ.apply(Ms, idx, v0, vT, S, scan)\n","    return -(logZ / target_lengths).mean()\n","\n","ctc_loss_py = partial(_ctc_loss, scan=Mv_scan_py)"],"execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"id":"MQ-2OXpkO4ad","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":50},"executionInfo":{"status":"ok","timestamp":1597312651862,"user_tz":-60,"elapsed":1016,"user":{"displayName":"david page","photoUrl":"","userId":"15385526310632231424"}},"outputId":"1356e82c-a2cf-4001-cd48-1724fbae1d20"},"source":["sample_inputs = logits, targets, input_lengths, target_lengths = generate_sample_inputs(T_min=500, T_max=500, N=128, C=20, L_min=80, L_max=100)\n","fwd, bwd = compare_fwd_bwd(loss_pytorch, ctc_loss_py, *sample_inputs)"],"execution_count":33,"outputs":[{"output_type":"stream","text":["fwd diff: 0.00e+00\n","bwd diff: 9.20e-08\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"a7ZLRSjCoG6i","colab_type":"text"},"source":["### 3. Cupy"]},{"cell_type":"code","metadata":{"id":"fzyYeFSfFPWU","colab_type":"code","colab":{}},"source":["%%writefile cuda/sparse.cu\n","__device__ __forceinline__ FLOAT max2(FLOAT a, FLOAT b) {return a > b ? a : b;}\n","__device__ __forceinline__ FLOAT logsumexp2(FLOAT a, FLOAT b) {return a > b ? log1p(exp(b - a)) + a : log1p(exp(a - b)) + b;}\n","__device__ __forceinline__ FLOAT add(FLOAT a, FLOAT b) {return a + b;}\n","\n","extern \"C\" __global__ void sparse_Mv_scan(\n","    FLOAT* __restrict__ alpha,\n","    const FLOAT* __restrict__ Ms,  \n","    const int* __restrict__ idx,\n","    int T, int N, int C, int nz\n",") {\n","    int bx = blockIdx.x, tx = threadIdx.x;\n","    if (tx >= C) return;\n","    extern __shared__ FLOAT smem[];\n","    \n","    FLOAT a = alpha[bx * C + tx];\n","    for (int t = 0; t < T; t++) {\n","        FLOAT *buf = smem + (t % 2) * blockDim.x;\n","        buf[tx] = a; __syncthreads();      \n","        int i = ((t * N + bx) * C) + tx;\n","        a = MUL(buf[idx[tx * nz]], Ms[i * nz]);\n","        for (int j = 1; j < nz; j++) {\n","            a = ADD(a, MUL(buf[idx[tx * nz + j]], Ms[i * nz + j]));\n","        }\n","        alpha[i + N * C] = a;\n","    }\n","}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qXMMQ-9WQbyZ","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597312940536,"user_tz":-60,"elapsed":611,"user":{"displayName":"david page","photoUrl":"","userId":"15385526310632231424"}}},"source":["#export\n","cupy_funcs = {\n","    (torch.float32, Log): load_cupy_func('cuda/sparse.cu', 'sparse_Mv_scan', FLOAT='float',  ADD='logsumexp2', MUL='add', ZERO='{:E}'.format(Log.zero)),\n","    (torch.float64, Log): load_cupy_func('cuda/sparse.cu', 'sparse_Mv_scan', FLOAT='double',  ADD='logsumexp2', MUL='add', ZERO='{:E}'.format(Log.zero)),\n","    (torch.float32, Max): load_cupy_func('cuda/sparse.cu', 'sparse_Mv_scan', FLOAT='float',  ADD='max2', MUL='add', ZERO='{:E}'.format(Log.zero)),\n","    (torch.float64, Max): load_cupy_func('cuda/sparse.cu', 'sparse_Mv_scan', FLOAT='double',  ADD='max2', MUL='add', ZERO='{:E}'.format(Log.zero)),\n","}\n","\n","def Mv_scan_cupy(Ms, idx, v0, S:semiring):\n","    T, N, C, nz = Ms.shape\n","    assert idx.shape == (C, nz) \n","    alpha = Ms.new_full((T+1, N, C), S.zero)\n","    alpha[0] = v0\n","    with cp.cuda.Device(Ms.device.index):\n","        cupy_funcs[(Ms.dtype, S)](grid=(N, 1, 1), block=(C, 1, 1), shared_mem=2*8*C,\n","               args=(alpha.data_ptr(), Ms.data_ptr(), idx.to(dtype=torch.int, device=Ms.device).data_ptr(), T, N, C, nz))\n","    return alpha\n","\n","logZ = partial(_LogZ.apply, S=Log, scan=Mv_scan_cupy)\n","\n","ctc_loss = partial(_ctc_loss, scan=Mv_scan_cupy)"],"execution_count":41,"outputs":[]},{"cell_type":"code","metadata":{"id":"buhZaRPlQ_bW","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":50},"executionInfo":{"status":"ok","timestamp":1597312950868,"user_tz":-60,"elapsed":1449,"user":{"displayName":"david page","photoUrl":"","userId":"15385526310632231424"}},"outputId":"cc6d79e2-2ad0-417a-c01e-a6511694ae83"},"source":["sample_inputs = logits, targets, input_lengths, target_lengths = generate_sample_inputs(T_min=500, T_max=500, N=128, C=20, L_min=80, L_max=100)\n","fwd, bwd = compare_fwd_bwd(loss_pytorch, ctc_loss, *sample_inputs)"],"execution_count":42,"outputs":[{"output_type":"stream","text":["fwd diff: 0.00e+00\n","bwd diff: 1.00e-07\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PybecCFhRZ0R","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":67},"executionInfo":{"status":"ok","timestamp":1597312976436,"user_tz":-60,"elapsed":571,"user":{"displayName":"david page","photoUrl":"","userId":"15385526310632231424"}},"outputId":"160ee9ce-0458-46a5-d595-5560bbd5e3e0"},"source":["report(benchmark_fwd_bwd(loss_pytorch, *sample_inputs))"],"execution_count":44,"outputs":[{"output_type":"stream","text":["fwd: 1.71ms (1.64-1.81ms)\n","bwd: 4.47ms (4.39-4.56ms)\n","tot: 6.18ms (6.02-6.36ms)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tbhWco7jRVx-","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":67},"executionInfo":{"status":"ok","timestamp":1597312967541,"user_tz":-60,"elapsed":1587,"user":{"displayName":"david page","photoUrl":"","userId":"15385526310632231424"}},"outputId":"acc3f16c-437a-42f3-d0e9-57f77f2211d4"},"source":["report(benchmark_fwd_bwd(ctc_loss, *sample_inputs))"],"execution_count":43,"outputs":[{"output_type":"stream","text":["fwd: 9.26ms (9.05-10.20ms)\n","bwd: 21.41ms (20.89-24.15ms)\n","tot: 30.67ms (29.94-34.32ms)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FQPrGxKpRcPI","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}