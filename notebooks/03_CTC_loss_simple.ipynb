{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"03_CTC_loss_simple.ipynb","provenance":[{"file_id":"12XP_WZ0yozRtpkmILZ8lJg8LYKx5jRbt","timestamp":1594981909636}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"view-in-github","colab_type":"text"},"source":["<a href=\"https://colab.research.google.com/github/davidcpage/mctc/blob/master/notebooks/01_CTC_loss.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"code","metadata":{"id":"5eu0cLH33Q09","colab_type":"code","colab":{}},"source":["# default_exp ctc_simple"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lwSCvHH9S_TO","colab_type":"text"},"source":["# CTC loss simple\n","\n","> A simplified CTC loss for decoding lattices with only two options stay/move. This can be used for decoding without collapsing of repeats."]},{"cell_type":"code","metadata":{"id":"3Rsd7qFH3rK7","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595257089108,"user_tz":-60,"elapsed":2059,"user":{"displayName":"david page","photoUrl":"","userId":"15385526310632231424"}}},"source":["#export\n","import numpy as np\n","import cupy as cp\n","import torch\n","import torch.nn as nn\n","from collections import namedtuple\n","from mctc.utils import *\n","\n","device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IfMZxoqjAzUd","colab_type":"text"},"source":["## Preliminaries"]},{"cell_type":"markdown","metadata":{"id":"f5QhUc8ErIKK","colab_type":"text"},"source":["Generate a test example:"]},{"cell_type":"code","metadata":{"id":"hKNBt8XDa9y6","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595257090019,"user_tz":-60,"elapsed":387,"user":{"displayName":"david page","photoUrl":"","userId":"15385526310632231424"}}},"source":["#export\n","def generate_sample_inputs(T, N, L_min, L_max, device=device):\n","    \"\"\"\n","    Args:\n","        T: number of time steps\n","        N: batch size\n","        L_min, L_max: bounds on target length\n","    \"\"\"\n","    stay_scores = torch.rand(T, N, L_max, device=device, requires_grad=True)\n","    move_scores = torch.rand(T, N, L_max-1, device=device, requires_grad=True)\n","    target_lengths = torch.randint(L_min, L_max+1, (N,), device=device)\n","    return stay_scores, move_scores, target_lengths"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"G1iRyJwqbWib","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595257099873,"user_tz":-60,"elapsed":8863,"user":{"displayName":"david page","photoUrl":"","userId":"15385526310632231424"}}},"source":["sample_inputs = stay_scores, move_scores, target_lengths = generate_sample_inputs(T=800, N=64, L_min=330, L_max=500)"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6FN28tVWEmsK","colab_type":"text"},"source":["## Loss implementations"]},{"cell_type":"markdown","metadata":{"id":"FmZa5QcOcEzC","colab_type":"text"},"source":["### 1. Basic pytorch"]},{"cell_type":"markdown","metadata":{"id":"rVkKq1yHvBBK","colab_type":"text"},"source":["Here's a straightforward implementation in pytorch in logspace.\n"]},{"cell_type":"code","metadata":{"id":"FF5IdGiMWNLc","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595257100633,"user_tz":-60,"elapsed":5763,"user":{"displayName":"david page","photoUrl":"","userId":"15385526310632231424"}}},"source":["#export\n","from torch.nn.functional import pad\n","from mctc.ctc import Log, semiring\n","\n","def logZ_fwd(stay_scores, move_scores, target_lengths, S=Log):\n","    T, N, L = stay_scores.shape\n","    alpha_0 = stay_scores.new_full((N, L), S.zero); alpha_0[:, 0] = S.one\n","    beta_T = stay_scores.new_full((N, L), S.zero); beta_T[torch.arange(N), target_lengths - 1] = S.one\n","    move_scores = pad(move_scores, (1, 0), value=S.zero)\n","    a = pad(alpha_0, (1, 0), value=S.zero)\n","    for t in range(0, stay_scores.size(0)):\n","        a[:, 1:] = S.sum(torch.stack([\n","            S.mul(stay_scores[t], a[:, 1:]),\n","            S.mul(move_scores[t], a[:, :-1])\n","        ]), dim=0)    \n","    return S.sum(S.mul(a[:, 1:], beta_T), dim=1)"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"nhDtvcY6WyaW","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":185},"executionInfo":{"status":"ok","timestamp":1594989018669,"user_tz":-60,"elapsed":872,"user":{"displayName":"david page","photoUrl":"","userId":"15385526310632231424"}},"outputId":"8c0d5749-6fa4-49e3-c712-837bec575bd0"},"source":["res = logZ_fwd(*sample_inputs)\n","res"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([974.2330, 984.3713, 984.7618, 983.5563, 977.9988, 980.5652, 982.5593,\n","        971.0525, 959.5686, 981.7110, 982.6719, 981.7672, 960.4211, 958.2485,\n","        970.2556, 958.7040, 980.2366, 959.4419, 982.2386, 981.1763, 980.1992,\n","        977.2121, 960.9742, 982.7201, 980.7336, 983.1967, 981.9204, 983.6624,\n","        984.1556, 984.8323, 976.8654, 966.7563, 968.9673, 970.4185, 980.5213,\n","        981.7200, 976.7703, 976.3128, 974.6606, 980.0289, 972.0240, 978.2053,\n","        971.4316, 969.5367, 969.0744, 975.5978, 968.7987, 973.7723, 971.9407,\n","        984.4995, 983.2872, 973.0983, 974.6730, 962.9532, 979.3806, 984.2042,\n","        975.2693, 972.7799, 968.5809, 981.6971, 978.7980, 982.7258, 980.3069,\n","        978.9800], device='cuda:0', grad_fn=<LogsumexpBackward>)"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"2SmEuWACD1Gw","colab_type":"code","colab":{}},"source":["#report(benchmark_fwd_bwd((lambda *x: logZ_fwd(*x).sum()), *sample_inputs))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eOyepFIsaL_z","colab_type":"text"},"source":["### 2. Pytorch with grad"]},{"cell_type":"code","metadata":{"id":"5tPPCYDgYDj3","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595257100634,"user_tz":-60,"elapsed":4205,"user":{"displayName":"david page","photoUrl":"","userId":"15385526310632231424"}}},"source":["#export\n","def _simple_lattice_fwd_bwd(alpha, beta_T, beta_stay, beta_move, stay_scores, move_scores, S=Log):\n","    T = alpha.size(0) - 1\n","    move_scores = pad(move_scores, (1, 1), value=S.zero)\n","    a = pad(alpha[0], (1, 0), value=S.zero)\n","    for t in range(0, T):\n","        a[:, 1:] = S.sum(torch.stack([\n","            S.mul(stay_scores[t], a[:, 1:]),\n","            S.mul(move_scores[t, :, :-1], a[:, :-1])\n","        ]), dim=0)\n","        alpha[t+1] = a[:, 1:]\n","    \n","    b = pad(beta_T, (0, 1), value=S.zero)\n","    for t in range(T, 0, -1):\n","        beta_stay[t-1] = S.mul(b[:, :-1], stay_scores[t - 1])\n","        beta_move[t-1] = S.mul(b[:, 1:], move_scores[t - 1, :, 1:])\n","        b[:, :-1] = S.sum(torch.stack([beta_stay[t-1], beta_move[t-1]]), dim=0)\n","\n","def dot(x, y, S=Log, dim=-1):\n","    return S.sum(S.mul(x, y), dim=dim) \n","\n","class LogZ(torch.autograd.Function):\n","    @staticmethod\n","    def forward(ctx, stay_scores, move_scores, target_lengths, fwd_bwd_impl):\n","        S = Log\n","        T, N, L = stay_scores.shape\n","        \n","        alpha = stay_scores.new_full((T + 1, N, L), S.zero) \n","        alpha[0, :, 0] = S.one \n","    \n","        beta_stay = stay_scores.new_full((T, N, L), S.zero)\n","        beta_move = stay_scores.new_full((T, N, L), S.zero)\n","        beta_T = stay_scores.new_full((N, L), S.zero) \n","        beta_T[torch.arange(N), target_lengths - 1] = S.one\n","        \n","        fwd_bwd_impl(alpha, beta_T, beta_stay, beta_move, stay_scores, move_scores, S) \n","        \n","        g = torch.softmax(torch.cat([S.mul(alpha[:-1], beta_stay), S.mul(alpha[:-1], beta_move)], dim=2), dim=2) #express softmax in terms of S?\n","        \n","        ctx.save_for_backward(g.reshape(T, N, 2, L))\n","        return dot(alpha[-1], beta_T, S)\n","\n","    @staticmethod\n","    def backward(ctx, grad):\n","        g = ctx.saved_tensors[0] * grad[None, :, None, None]\n","        return g[:, :, 0], g[:, :, 1, :-1], None, None\n","\n","def logZ_py(stay_scores, move_scores, target_lengths):\n","    return LogZ.apply(stay_scores, move_scores, target_lengths, _simple_lattice_fwd_bwd)"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"pAjA3_--cJeh","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595257100634,"user_tz":-60,"elapsed":2287,"user":{"displayName":"david page","photoUrl":"","userId":"15385526310632231424"}}},"source":["#export\n","mean = lambda f: (lambda *xs: f(*xs).mean())"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"JG5eP5EtkKeW","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":50},"executionInfo":{"status":"ok","timestamp":1594989034005,"user_tz":-60,"elapsed":11523,"user":{"displayName":"david page","photoUrl":"","userId":"15385526310632231424"}},"outputId":"dd85f289-5e2b-4742-accb-1de35f0c7b69"},"source":["fwds, bwds = compare_fwd_bwd(float64(mean(logZ_fwd)), float64(mean(logZ_py)), *sample_inputs)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["fwd diff: 0.00e+00\n","bwd diff: 1.16e-10\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"a7ZLRSjCoG6i","colab_type":"text"},"source":["### 3. Cupy"]},{"cell_type":"markdown","metadata":{"id":"-AuStb1kvSkP","colab_type":"text"},"source":["NB: we defined beta_move to have size (T, N, L) not the more natural (T, N, L - 1) above. We did this so that we can stack it with beta_stay."]},{"cell_type":"code","metadata":{"id":"fzyYeFSfFPWU","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1595257503831,"user_tz":-60,"elapsed":530,"user":{"displayName":"david page","photoUrl":"","userId":"15385526310632231424"}},"outputId":"8bd647fa-a938-4e1f-ed72-3c005ac65636"},"source":["%%writefile mctc/cuda/ctc_simple.cu\n","__device__ __forceinline__ FLOAT max2(FLOAT a, FLOAT a1) {\n","    return a > a1 ? a : a1; \n","}\n","\n","__device__ __forceinline__ FLOAT logsumexp2(FLOAT a, FLOAT a1) {\n","    FLOAT maxa = max2(a, a1); \n","    return maxa + log(exp(a-maxa) + exp(a1-maxa));\n","}\n","\n","__device__ __forceinline__ FLOAT add(FLOAT a, FLOAT b) {return a + b;}\n","__device__ __forceinline__ FLOAT mul(FLOAT a, FLOAT b) {return a * b;}\n","\n","extern \"C\" __global__ void fwd_bwd_logspace(\n","    FLOAT* __restrict__ alpha, FLOAT* __restrict__ beta_T,\n","    FLOAT* __restrict__ beta_stay, FLOAT* __restrict__ beta_move, \n","    const FLOAT* __restrict__ stay_scores, const FLOAT* __restrict__ move_scores,\n","    int T, int N, int L\n",") {\n","    int bx = blockIdx.x, tx = threadIdx.x;\n","    if (tx >= L) return;\n","    extern __shared__ FLOAT smem[];\n","    if (blockIdx.y == 0) {\n","        FLOAT a = ZERO, a1 = ZERO;\n","        a = alpha[bx * L + tx];\n","        for (int t = 0; t < T; t++) {\n","            FLOAT *buf = smem + (t % 2) * blockDim.x;\n","            buf[tx] = a; __syncthreads(); \n","            if (tx > 0) {a1 = MUL(move_scores[(t * N + bx) * (L - 1) + tx - 1], buf[tx - 1]);}\n","            a = SUM(MUL(stay_scores[(t * N + bx) * L + tx], a), a1);\n","            alpha[((t + 1) * N + bx) * L + tx] = a;\n","        }\n","    }\n","    else {\n","        FLOAT b = ZERO, b1 = ZERO;\n","        b = beta_T[bx * L + tx];\n","        for (int t = T; t > 0; t--) {\n","            FLOAT *buf = smem + (t % 2) * blockDim.x;\n","            buf[tx] = b; __syncthreads();\n","            if (tx < L - 1) {\n","                b1 = MUL(buf[tx + 1], move_scores[(((t - 1) * N + bx) * (L - 1)) + tx]);\n","                beta_move[((t - 1) * N + bx) * L + tx] = b1;\n","            }\n","            b = MUL(b, stay_scores[(((t - 1) * N + bx) * L) + tx]);\n","            beta_stay[((t - 1) * N + bx) * L + tx] = b;\n","            b = SUM(b, b1);\n","        }\n","    }\n","  }"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Overwriting mctc/cuda/ctc_simple.cu\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"02YPMAOyMFhi","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595257506120,"user_tz":-60,"elapsed":525,"user":{"displayName":"david page","photoUrl":"","userId":"15385526310632231424"}}},"source":["#export\n","from mctc.utils import *\n","import cupy as cp\n","\n","cupy_funcs = {\n","    (torch.float32, Log): load_cupy_func('cuda/ctc_simple.cu', 'fwd_bwd_logspace', FLOAT='float',  SUM='logsumexp2', MUL='add', ZERO='{:E}'.format(Log.zero)),\n","    (torch.float64, Log): load_cupy_func('cuda/ctc_simple.cu', 'fwd_bwd_logspace', FLOAT='double', SUM='logsumexp2', MUL='add', ZERO='{:E}'.format(Log.zero)),\n","}\n","\n","def _simple_lattice_fwd_bwd_cupy(alpha, beta_T, beta_stay, beta_move, stay_scores, move_scores, S:semiring):\n","    T, N, L = stay_scores.shape\n","    with cp.cuda.Device(stay_scores.device.index):\n","        cupy_funcs[(stay_scores.dtype, S)](grid=(N, 2, 1), block=(L, 1, 1), shared_mem=2*8*L,\n","               args=(alpha.data_ptr(), beta_T.data_ptr(), beta_stay.data_ptr(), beta_move.data_ptr(), \n","                     stay_scores.data_ptr(), move_scores.data_ptr(), T, N, L))\n","\n","def logZ_cupy(stay_scores, move_scores, target_lengths):\n","    return LogZ.apply(stay_scores, move_scores, target_lengths, _simple_lattice_fwd_bwd_cupy)"],"execution_count":45,"outputs":[]},{"cell_type":"code","metadata":{"id":"AP6kt-4kdcuP","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":50},"executionInfo":{"status":"ok","timestamp":1595257452433,"user_tz":-60,"elapsed":1327,"user":{"displayName":"david page","photoUrl":"","userId":"15385526310632231424"}},"outputId":"0452474b-b4b7-4920-87f3-f400e9cc9be8"},"source":["fwds, bwds = compare_fwd_bwd(float64(mean(logZ_py)), float64(mean(logZ_cupy)), *sample_inputs)"],"execution_count":41,"outputs":[{"output_type":"stream","text":["fwd diff: 0.00e+00\n","bwd diff: 0.00e+00\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"j4Gl3tE8MXvD","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":67},"executionInfo":{"status":"ok","timestamp":1595257415169,"user_tz":-60,"elapsed":4065,"user":{"displayName":"david page","photoUrl":"","userId":"15385526310632231424"}},"outputId":"83a7dfdb-e76b-4339-b145-a5db99812fa0"},"source":["report(benchmark_fwd_bwd(mean(logZ_cupy), *sample_inputs, nloops=100))"],"execution_count":34,"outputs":[{"output_type":"stream","text":["fwd: 19.56ms (19.31-21.06ms)\n","bwd: 7.53ms (7.40-8.05ms)\n","tot: 27.10ms (26.81-29.11ms)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"w5yZG53Vwdba","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}