---

title: CTC loss simple

keywords: fastai
sidebar: home_sidebar

summary: "A simplified CTC loss for decoding lattices with only two options stay/move. This can be used for decoding without collapsing of repeats."
description: "A simplified CTC loss for decoding lattices with only two options stay/move. This can be used for decoding without collapsing of repeats."
nb_path: "notebooks/04_CTC_loss_simple.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: notebooks/04_CTC_loss_simple.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a href="https://colab.research.google.com/github/davidcpage/seqdist/blob/master/notebooks/01_CTC_loss.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a></p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Preliminaries">Preliminaries<a class="anchor-link" href="#Preliminaries"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Generate a test example:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="generate_sample_inputs" class="doc_header"><code>generate_sample_inputs</code><a href="https://github.com/davidcpage/seqdist/tree/master/seqdist/ctc_simple.py#L17" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>generate_sample_inputs</code>(<strong><code>T</code></strong>, <strong><code>N</code></strong>, <strong><code>L_min</code></strong>, <strong><code>L_max</code></strong>, <strong><code>device</code></strong>=<em><code>device(type='cuda')</code></em>)</p>
</blockquote>
<p>Args:
    T: number of time steps
    N: batch size
    L_min, L_max: bounds on target length</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">sample_inputs</span> <span class="o">=</span> <span class="n">stay_scores</span><span class="p">,</span> <span class="n">move_scores</span><span class="p">,</span> <span class="n">target_lengths</span> <span class="o">=</span> <span class="n">generate_sample_inputs</span><span class="p">(</span><span class="n">T</span><span class="o">=</span><span class="mi">800</span><span class="p">,</span> <span class="n">N</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">L_min</span><span class="o">=</span><span class="mi">330</span><span class="p">,</span> <span class="n">L_max</span><span class="o">=</span><span class="mi">500</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Loss-implementations">Loss implementations<a class="anchor-link" href="#Loss-implementations"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="1.-Basic-pytorch">1. Basic pytorch<a class="anchor-link" href="#1.-Basic-pytorch"> </a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Here's a straightforward implementation in pytorch in logspace.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="logZ_fwd" class="doc_header"><code>logZ_fwd</code><a href="__main__.py#L5" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>logZ_fwd</code>(<strong><code>stay_scores</code></strong>, <strong><code>move_scores</code></strong>, <strong><code>target_lengths</code></strong>, <strong><code>S</code></strong>=<em><code>semiring(zero=-1e+38, one=0.0, mul=&lt;built-in method add of type object at 0x7fc6973a2320&gt;, sum=&lt;built-in method logsumexp of type object at 0x7fc6973a2320&gt;, dsum=&lt;built-in method softmax of type object at 0x7fc6973a2320&gt;)</code></em>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">res</span> <span class="o">=</span> <span class="n">logZ_fwd</span><span class="p">(</span><span class="o">*</span><span class="n">sample_inputs</span><span class="p">)</span>
<span class="n">res</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor([974.2330, 984.3713, 984.7618, 983.5563, 977.9988, 980.5652, 982.5593,
        971.0525, 959.5686, 981.7110, 982.6719, 981.7672, 960.4211, 958.2485,
        970.2556, 958.7040, 980.2366, 959.4419, 982.2386, 981.1763, 980.1992,
        977.2121, 960.9742, 982.7201, 980.7336, 983.1967, 981.9204, 983.6624,
        984.1556, 984.8323, 976.8654, 966.7563, 968.9673, 970.4185, 980.5213,
        981.7200, 976.7703, 976.3128, 974.6606, 980.0289, 972.0240, 978.2053,
        971.4316, 969.5367, 969.0744, 975.5978, 968.7987, 973.7723, 971.9407,
        984.4995, 983.2872, 973.0983, 974.6730, 962.9532, 979.3806, 984.2042,
        975.2693, 972.7799, 968.5809, 981.6971, 978.7980, 982.7258, 980.3069,
        978.9800], device=&#39;cuda:0&#39;, grad_fn=&lt;LogsumexpBackward&gt;)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="2.-Pytorch-with-grad">2. Pytorch with grad<a class="anchor-link" href="#2.-Pytorch-with-grad"> </a></h3>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="dot" class="doc_header"><code>dot</code><a href="https://github.com/davidcpage/seqdist/tree/master/seqdist/ctc_simple.py#L64" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>dot</code>(<strong><code>x</code></strong>, <strong><code>y</code></strong>, <strong><code>S</code></strong>=<em><code>semiring(zero=-1e+38, one=0.0, mul=&lt;built-in method add of type object at 0x7fc6973a2320&gt;, sum=&lt;built-in method logsumexp of type object at 0x7fc6973a2320&gt;, dsum=&lt;built-in method softmax of type object at 0x7fc6973a2320&gt;)</code></em>, <strong><code>dim</code></strong>=<em><code>-1</code></em>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="LogZ" class="doc_header"><code>class</code> <code>LogZ</code><a href="https://github.com/davidcpage/seqdist/tree/master/seqdist/ctc_simple.py#L67" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>LogZ</code>() :: <code>Function</code></p>
</blockquote>
<p>Records operation history and defines formulas for differentiating ops.</p>
<p>Every operation performed on :class:<code>Tensor</code> s creates a new function
object, that performs the computation, and records that it happened.
The history is retained in the form of a DAG of functions, with edges
denoting data dependencies (<code>input &lt;- output</code>). Then, when backward is
called, the graph is processed in the topological ordering, by calling
:func:<code>backward</code> methods of each :class:<code>Function</code> object, and passing
returned gradients on to next :class:<code>Function</code> s.</p>
<p>Normally, the only way users interact with functions is by creating
subclasses and defining new operations. This is a recommended way of
extending torch.autograd.</p>
<p>Examples::</p>

<pre><code>&gt;&gt;&gt; class Exp(Function):
&gt;&gt;&gt;
&gt;&gt;&gt;     @staticmethod
&gt;&gt;&gt;     def forward(ctx, i):
&gt;&gt;&gt;         result = i.exp()
&gt;&gt;&gt;         ctx.save_for_backward(result)
&gt;&gt;&gt;         return result
&gt;&gt;&gt;
&gt;&gt;&gt;     @staticmethod
&gt;&gt;&gt;     def backward(ctx, grad_output):
&gt;&gt;&gt;         result, = ctx.saved_tensors
&gt;&gt;&gt;         return grad_output * result
&gt;&gt;&gt;
&gt;&gt;&gt; #Use it by calling the apply method:
&gt;&gt;&gt; output = Exp.apply(input)</code></pre>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="logZ_py" class="doc_header"><code>logZ_py</code><a href="https://github.com/davidcpage/seqdist/tree/master/seqdist/ctc_simple.py#L92" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>logZ_py</code>(<strong><code>stay_scores</code></strong>, <strong><code>move_scores</code></strong>, <strong><code>target_lengths</code></strong>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">fwds</span><span class="p">,</span> <span class="n">bwds</span> <span class="o">=</span> <span class="n">compare_fwd_bwd</span><span class="p">(</span><span class="n">float64</span><span class="p">(</span><span class="n">mean</span><span class="p">(</span><span class="n">logZ_fwd</span><span class="p">)),</span> <span class="n">float64</span><span class="p">(</span><span class="n">mean</span><span class="p">(</span><span class="n">logZ_py</span><span class="p">)),</span> <span class="o">*</span><span class="n">sample_inputs</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>fwd diff: 0.00e+00
bwd diff: 1.16e-10
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="3.-Cupy">3. Cupy<a class="anchor-link" href="#3.-Cupy"> </a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>NB: we defined beta_move to have size (T, N, L) not the more natural (T, N, L - 1) above. We did this so that we can stack it with beta_stay.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%%writefile</span> seqdist/cuda/ctc_simple.cu
<span class="n">__device__</span> <span class="n">__forceinline__</span> <span class="n">FLOAT</span> <span class="n">max2</span><span class="p">(</span><span class="n">FLOAT</span> <span class="n">a</span><span class="p">,</span> <span class="n">FLOAT</span> <span class="n">a1</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">a</span> <span class="o">&gt;</span> <span class="n">a1</span> <span class="err">?</span> <span class="n">a</span> <span class="p">:</span> <span class="n">a1</span><span class="p">;</span> 
<span class="p">}</span>

<span class="n">__device__</span> <span class="n">__forceinline__</span> <span class="n">FLOAT</span> <span class="n">logsumexp2</span><span class="p">(</span><span class="n">FLOAT</span> <span class="n">a</span><span class="p">,</span> <span class="n">FLOAT</span> <span class="n">a1</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">FLOAT</span> <span class="n">maxa</span> <span class="o">=</span> <span class="n">max2</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">a1</span><span class="p">);</span> 
    <span class="k">return</span> <span class="n">maxa</span> <span class="o">+</span> <span class="n">log</span><span class="p">(</span><span class="n">exp</span><span class="p">(</span><span class="n">a</span><span class="o">-</span><span class="n">maxa</span><span class="p">)</span> <span class="o">+</span> <span class="n">exp</span><span class="p">(</span><span class="n">a1</span><span class="o">-</span><span class="n">maxa</span><span class="p">));</span>
<span class="p">}</span>

<span class="n">__device__</span> <span class="n">__forceinline__</span> <span class="n">FLOAT</span> <span class="n">add</span><span class="p">(</span><span class="n">FLOAT</span> <span class="n">a</span><span class="p">,</span> <span class="n">FLOAT</span> <span class="n">b</span><span class="p">)</span> <span class="p">{</span><span class="k">return</span> <span class="n">a</span> <span class="o">+</span> <span class="n">b</span><span class="p">;}</span>
<span class="n">__device__</span> <span class="n">__forceinline__</span> <span class="n">FLOAT</span> <span class="n">mul</span><span class="p">(</span><span class="n">FLOAT</span> <span class="n">a</span><span class="p">,</span> <span class="n">FLOAT</span> <span class="n">b</span><span class="p">)</span> <span class="p">{</span><span class="k">return</span> <span class="n">a</span> <span class="o">*</span> <span class="n">b</span><span class="p">;}</span>

<span class="n">extern</span> <span class="s2">&quot;C&quot;</span> <span class="n">__global__</span> <span class="n">void</span> <span class="n">fwd_bwd_logspace</span><span class="p">(</span>
    <span class="n">FLOAT</span><span class="o">*</span> <span class="n">__restrict__</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">FLOAT</span><span class="o">*</span> <span class="n">__restrict__</span> <span class="n">beta_T</span><span class="p">,</span>
    <span class="n">FLOAT</span><span class="o">*</span> <span class="n">__restrict__</span> <span class="n">beta_stay</span><span class="p">,</span> <span class="n">FLOAT</span><span class="o">*</span> <span class="n">__restrict__</span> <span class="n">beta_move</span><span class="p">,</span> 
    <span class="n">const</span> <span class="n">FLOAT</span><span class="o">*</span> <span class="n">__restrict__</span> <span class="n">stay_scores</span><span class="p">,</span> <span class="n">const</span> <span class="n">FLOAT</span><span class="o">*</span> <span class="n">__restrict__</span> <span class="n">move_scores</span><span class="p">,</span>
    <span class="nb">int</span> <span class="n">T</span><span class="p">,</span> <span class="nb">int</span> <span class="n">N</span><span class="p">,</span> <span class="nb">int</span> <span class="n">L</span>
<span class="p">)</span> <span class="p">{</span>
    <span class="nb">int</span> <span class="n">bx</span> <span class="o">=</span> <span class="n">blockIdx</span><span class="o">.</span><span class="n">x</span><span class="p">,</span> <span class="n">tx</span> <span class="o">=</span> <span class="n">threadIdx</span><span class="o">.</span><span class="n">x</span><span class="p">;</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">tx</span> <span class="o">&gt;=</span> <span class="n">L</span><span class="p">)</span> <span class="k">return</span><span class="p">;</span>
    <span class="n">extern</span> <span class="n">__shared__</span> <span class="n">FLOAT</span> <span class="n">smem</span><span class="p">[];</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">blockIdx</span><span class="o">.</span><span class="n">y</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">FLOAT</span> <span class="n">a</span> <span class="o">=</span> <span class="n">ZERO</span><span class="p">,</span> <span class="n">a1</span> <span class="o">=</span> <span class="n">ZERO</span><span class="p">;</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">alpha</span><span class="p">[</span><span class="n">bx</span> <span class="o">*</span> <span class="n">L</span> <span class="o">+</span> <span class="n">tx</span><span class="p">];</span>
        <span class="k">for</span> <span class="p">(</span><span class="nb">int</span> <span class="n">t</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">t</span> <span class="o">&lt;</span> <span class="n">T</span><span class="p">;</span> <span class="n">t</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
            <span class="n">FLOAT</span> <span class="o">*</span><span class="n">buf</span> <span class="o">=</span> <span class="n">smem</span> <span class="o">+</span> <span class="p">(</span><span class="n">t</span> <span class="o">%</span> <span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="n">blockDim</span><span class="o">.</span><span class="n">x</span><span class="p">;</span>
            <span class="n">buf</span><span class="p">[</span><span class="n">tx</span><span class="p">]</span> <span class="o">=</span> <span class="n">a</span><span class="p">;</span> <span class="n">__syncthreads</span><span class="p">();</span> 
            <span class="k">if</span> <span class="p">(</span><span class="n">tx</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span><span class="n">a1</span> <span class="o">=</span> <span class="n">MUL</span><span class="p">(</span><span class="n">move_scores</span><span class="p">[(</span><span class="n">t</span> <span class="o">*</span> <span class="n">N</span> <span class="o">+</span> <span class="n">bx</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">L</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="n">tx</span> <span class="o">-</span> <span class="mi">1</span><span class="p">],</span> <span class="n">buf</span><span class="p">[</span><span class="n">tx</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]);}</span>
            <span class="n">a</span> <span class="o">=</span> <span class="n">SUM</span><span class="p">(</span><span class="n">MUL</span><span class="p">(</span><span class="n">stay_scores</span><span class="p">[(</span><span class="n">t</span> <span class="o">*</span> <span class="n">N</span> <span class="o">+</span> <span class="n">bx</span><span class="p">)</span> <span class="o">*</span> <span class="n">L</span> <span class="o">+</span> <span class="n">tx</span><span class="p">],</span> <span class="n">a</span><span class="p">),</span> <span class="n">a1</span><span class="p">);</span>
            <span class="n">alpha</span><span class="p">[((</span><span class="n">t</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">N</span> <span class="o">+</span> <span class="n">bx</span><span class="p">)</span> <span class="o">*</span> <span class="n">L</span> <span class="o">+</span> <span class="n">tx</span><span class="p">]</span> <span class="o">=</span> <span class="n">a</span><span class="p">;</span>
        <span class="p">}</span>
    <span class="p">}</span>
    <span class="k">else</span> <span class="p">{</span>
        <span class="n">FLOAT</span> <span class="n">b</span> <span class="o">=</span> <span class="n">ZERO</span><span class="p">,</span> <span class="n">b1</span> <span class="o">=</span> <span class="n">ZERO</span><span class="p">;</span>
        <span class="n">b</span> <span class="o">=</span> <span class="n">beta_T</span><span class="p">[</span><span class="n">bx</span> <span class="o">*</span> <span class="n">L</span> <span class="o">+</span> <span class="n">tx</span><span class="p">];</span>
        <span class="k">for</span> <span class="p">(</span><span class="nb">int</span> <span class="n">t</span> <span class="o">=</span> <span class="n">T</span><span class="p">;</span> <span class="n">t</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">;</span> <span class="n">t</span><span class="o">--</span><span class="p">)</span> <span class="p">{</span>
            <span class="n">FLOAT</span> <span class="o">*</span><span class="n">buf</span> <span class="o">=</span> <span class="n">smem</span> <span class="o">+</span> <span class="p">(</span><span class="n">t</span> <span class="o">%</span> <span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="n">blockDim</span><span class="o">.</span><span class="n">x</span><span class="p">;</span>
            <span class="n">buf</span><span class="p">[</span><span class="n">tx</span><span class="p">]</span> <span class="o">=</span> <span class="n">b</span><span class="p">;</span> <span class="n">__syncthreads</span><span class="p">();</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">tx</span> <span class="o">&lt;</span> <span class="n">L</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
                <span class="n">b1</span> <span class="o">=</span> <span class="n">MUL</span><span class="p">(</span><span class="n">buf</span><span class="p">[</span><span class="n">tx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">],</span> <span class="n">move_scores</span><span class="p">[(((</span><span class="n">t</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">N</span> <span class="o">+</span> <span class="n">bx</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">L</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span> <span class="o">+</span> <span class="n">tx</span><span class="p">]);</span>
                <span class="n">beta_move</span><span class="p">[((</span><span class="n">t</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">N</span> <span class="o">+</span> <span class="n">bx</span><span class="p">)</span> <span class="o">*</span> <span class="n">L</span> <span class="o">+</span> <span class="n">tx</span><span class="p">]</span> <span class="o">=</span> <span class="n">b1</span><span class="p">;</span>
            <span class="p">}</span>
            <span class="n">b</span> <span class="o">=</span> <span class="n">MUL</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">stay_scores</span><span class="p">[(((</span><span class="n">t</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">N</span> <span class="o">+</span> <span class="n">bx</span><span class="p">)</span> <span class="o">*</span> <span class="n">L</span><span class="p">)</span> <span class="o">+</span> <span class="n">tx</span><span class="p">]);</span>
            <span class="n">beta_stay</span><span class="p">[((</span><span class="n">t</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">N</span> <span class="o">+</span> <span class="n">bx</span><span class="p">)</span> <span class="o">*</span> <span class="n">L</span> <span class="o">+</span> <span class="n">tx</span><span class="p">]</span> <span class="o">=</span> <span class="n">b</span><span class="p">;</span>
            <span class="n">b</span> <span class="o">=</span> <span class="n">SUM</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">b1</span><span class="p">);</span>
        <span class="p">}</span>
    <span class="p">}</span>
  <span class="p">}</span>

<span class="n">extern</span> <span class="s2">&quot;C&quot;</span> <span class="n">__global__</span> <span class="n">void</span> <span class="n">fwd_bwd_logspace_loop</span><span class="p">(</span>
    <span class="n">FLOAT</span><span class="o">*</span> <span class="n">__restrict__</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">FLOAT</span><span class="o">*</span> <span class="n">__restrict__</span> <span class="n">beta</span><span class="p">,</span>
    <span class="n">FLOAT</span><span class="o">*</span> <span class="n">__restrict__</span> <span class="n">beta_stay</span><span class="p">,</span> <span class="n">FLOAT</span><span class="o">*</span> <span class="n">__restrict__</span> <span class="n">beta_move</span><span class="p">,</span> 
    <span class="n">const</span> <span class="n">FLOAT</span><span class="o">*</span> <span class="n">__restrict__</span> <span class="n">stay_scores</span><span class="p">,</span> <span class="n">const</span> <span class="n">FLOAT</span><span class="o">*</span> <span class="n">__restrict__</span> <span class="n">move_scores</span><span class="p">,</span>
    <span class="nb">int</span> <span class="n">T</span><span class="p">,</span> <span class="nb">int</span> <span class="n">N</span><span class="p">,</span> <span class="nb">int</span> <span class="n">L</span>
<span class="p">)</span> <span class="p">{</span>
    <span class="nb">int</span> <span class="n">bx</span> <span class="o">=</span> <span class="n">blockIdx</span><span class="o">.</span><span class="n">x</span><span class="p">,</span> <span class="n">tx</span> <span class="o">=</span> <span class="n">threadIdx</span><span class="o">.</span><span class="n">x</span><span class="p">;</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">blockIdx</span><span class="o">.</span><span class="n">y</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">FLOAT</span> <span class="n">a</span><span class="p">;</span>
        <span class="k">for</span> <span class="p">(</span><span class="nb">int</span> <span class="n">t</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">t</span> <span class="o">&lt;</span> <span class="n">T</span><span class="p">;</span> <span class="n">t</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
            <span class="k">for</span> <span class="p">(</span><span class="nb">int</span> <span class="n">j</span> <span class="o">=</span> <span class="n">tx</span><span class="p">;</span> <span class="n">j</span> <span class="o">&lt;</span> <span class="n">L</span><span class="p">;</span> <span class="n">j</span> <span class="o">+=</span> <span class="n">blockDim</span><span class="o">.</span><span class="n">x</span><span class="p">)</span> <span class="p">{</span>
                <span class="n">a</span> <span class="o">=</span> <span class="p">(</span><span class="n">j</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span> <span class="err">?</span> <span class="n">MUL</span><span class="p">(</span><span class="n">move_scores</span><span class="p">[(</span><span class="n">t</span> <span class="o">*</span> <span class="n">N</span> <span class="o">+</span> <span class="n">bx</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">L</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="n">j</span> <span class="o">-</span> <span class="mi">1</span><span class="p">],</span> <span class="n">alpha</span><span class="p">[(</span><span class="n">t</span> <span class="o">*</span> <span class="n">N</span> <span class="o">+</span> <span class="n">bx</span><span class="p">)</span> <span class="o">*</span> <span class="n">L</span> <span class="o">+</span> <span class="n">j</span> <span class="o">-</span> <span class="mi">1</span><span class="p">])</span> <span class="p">:</span> <span class="n">ZERO</span><span class="p">;</span>
                <span class="n">alpha</span><span class="p">[((</span><span class="n">t</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">N</span> <span class="o">+</span> <span class="n">bx</span><span class="p">)</span> <span class="o">*</span> <span class="n">L</span> <span class="o">+</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">SUM</span><span class="p">(</span><span class="n">MUL</span><span class="p">(</span><span class="n">stay_scores</span><span class="p">[(</span><span class="n">t</span> <span class="o">*</span> <span class="n">N</span> <span class="o">+</span> <span class="n">bx</span><span class="p">)</span> <span class="o">*</span> <span class="n">L</span> <span class="o">+</span> <span class="n">j</span><span class="p">],</span> <span class="n">alpha</span><span class="p">[(</span><span class="n">t</span> <span class="o">*</span> <span class="n">N</span> <span class="o">+</span> <span class="n">bx</span><span class="p">)</span> <span class="o">*</span> <span class="n">L</span> <span class="o">+</span> <span class="n">j</span><span class="p">]),</span> <span class="n">a</span><span class="p">);</span>
            <span class="p">}</span>
            <span class="n">__syncthreads</span><span class="p">();</span>
        <span class="p">}</span>
    <span class="p">}</span>
    <span class="k">else</span> <span class="p">{</span>
        <span class="n">FLOAT</span> <span class="n">b</span><span class="p">,</span> <span class="n">b1</span><span class="p">;</span>
        <span class="k">for</span> <span class="p">(</span><span class="nb">int</span> <span class="n">t</span> <span class="o">=</span> <span class="n">T</span><span class="p">;</span> <span class="n">t</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">;</span> <span class="n">t</span><span class="o">--</span><span class="p">)</span> <span class="p">{</span>
            <span class="k">for</span> <span class="p">(</span><span class="nb">int</span> <span class="n">j</span> <span class="o">=</span> <span class="n">L</span> <span class="o">-</span> <span class="n">blockDim</span><span class="o">.</span><span class="n">x</span> <span class="o">+</span> <span class="n">tx</span><span class="p">;</span> <span class="n">j</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">j</span> <span class="o">-=</span> <span class="n">blockDim</span><span class="o">.</span><span class="n">x</span><span class="p">)</span> <span class="p">{</span>
                <span class="n">b1</span> <span class="o">=</span> <span class="n">ZERO</span><span class="p">;</span>
                <span class="k">if</span> <span class="p">(</span><span class="n">j</span> <span class="o">&lt;</span> <span class="n">L</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
                    <span class="n">b1</span> <span class="o">=</span> <span class="n">MUL</span><span class="p">(</span><span class="n">beta</span><span class="p">[(</span><span class="n">t</span> <span class="o">*</span> <span class="n">N</span> <span class="o">+</span> <span class="n">bx</span><span class="p">)</span> <span class="o">*</span> <span class="n">L</span> <span class="o">+</span> <span class="n">j</span> <span class="o">+</span> <span class="mi">1</span><span class="p">],</span> <span class="n">move_scores</span><span class="p">[(((</span><span class="n">t</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">N</span> <span class="o">+</span> <span class="n">bx</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">L</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span> <span class="o">+</span> <span class="n">j</span><span class="p">]);</span>
                    <span class="n">beta_move</span><span class="p">[((</span><span class="n">t</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">N</span> <span class="o">+</span> <span class="n">bx</span><span class="p">)</span> <span class="o">*</span> <span class="n">L</span> <span class="o">+</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">b1</span><span class="p">;</span>
                <span class="p">}</span>
                <span class="n">b</span> <span class="o">=</span> <span class="n">MUL</span><span class="p">(</span><span class="n">beta</span><span class="p">[(</span><span class="n">t</span> <span class="o">*</span> <span class="n">N</span> <span class="o">+</span> <span class="n">bx</span><span class="p">)</span> <span class="o">*</span> <span class="n">L</span> <span class="o">+</span> <span class="n">j</span><span class="p">],</span> <span class="n">stay_scores</span><span class="p">[(((</span><span class="n">t</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">N</span> <span class="o">+</span> <span class="n">bx</span><span class="p">)</span> <span class="o">*</span> <span class="n">L</span><span class="p">)</span> <span class="o">+</span> <span class="n">j</span><span class="p">]);</span>
                <span class="n">beta_stay</span><span class="p">[((</span><span class="n">t</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">N</span> <span class="o">+</span> <span class="n">bx</span><span class="p">)</span> <span class="o">*</span> <span class="n">L</span> <span class="o">+</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">b</span><span class="p">;</span>
                <span class="n">beta</span><span class="p">[((</span><span class="n">t</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">N</span> <span class="o">+</span> <span class="n">bx</span><span class="p">)</span> <span class="o">*</span> <span class="n">L</span> <span class="o">+</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">SUM</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">b1</span><span class="p">);</span>
            <span class="p">}</span>
            <span class="n">__syncthreads</span><span class="p">();</span>
        <span class="p">}</span>
    <span class="p">}</span>
  <span class="p">}</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="logZ_cupy" class="doc_header"><code>logZ_cupy</code><a href="__main__.py#L39" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>logZ_cupy</code>(<strong><code>stay_scores</code></strong>, <strong><code>move_scores</code></strong>, <strong><code>target_lengths</code></strong>, <strong><code>S</code></strong>:<a href="/seqdist/core.html#semiring"><code>semiring</code></a>=<em><code>semiring(zero=-1e+38, one=0.0, mul=&lt;built-in method add of type object at 0x7fc6973a2320&gt;, sum=&lt;built-in method logsumexp of type object at 0x7fc6973a2320&gt;, dsum=&lt;built-in method softmax of type object at 0x7fc6973a2320&gt;)</code></em>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="viterbi_alignments" class="doc_header"><code>viterbi_alignments</code><a href="__main__.py#L42" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>viterbi_alignments</code>(<strong><code>stay_scores</code></strong>, <strong><code>move_scores</code></strong>, <strong><code>target_lengths</code></strong>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">fwds</span><span class="p">,</span> <span class="n">bwds</span> <span class="o">=</span> <span class="n">compare_fwd_bwd</span><span class="p">(</span><span class="n">float64</span><span class="p">(</span><span class="n">mean</span><span class="p">(</span><span class="n">logZ_py</span><span class="p">)),</span> <span class="n">float64</span><span class="p">(</span><span class="n">mean</span><span class="p">(</span><span class="n">logZ_cupy</span><span class="p">)),</span> <span class="o">*</span><span class="n">sample_inputs</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>fwd diff: 0.00e+00
bwd diff: 0.00e+00
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">report</span><span class="p">(</span><span class="n">benchmark_fwd_bwd</span><span class="p">(</span><span class="n">mean</span><span class="p">(</span><span class="n">logZ_cupy</span><span class="p">),</span> <span class="o">*</span><span class="n">sample_inputs</span><span class="p">,</span> <span class="n">nloops</span><span class="o">=</span><span class="mi">100</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>fwd: 19.56ms (19.31-21.06ms)
bwd: 7.53ms (7.40-8.05ms)
tot: 27.10ms (26.81-29.11ms)
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

</div>
 

