---

title: CTC loss simple

keywords: fastai
sidebar: home_sidebar

summary: "A simplified CTC loss for decoding lattices with only two options stay/move. This can be used for decoding without collapsing of repeats."
description: "A simplified CTC loss for decoding lattices with only two options stay/move. This can be used for decoding without collapsing of repeats."
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: notebooks/03_CTC_loss_simple.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a href="https://colab.research.google.com/github/davidcpage/mctc/blob/master/notebooks/01_CTC_loss.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a></p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Preliminaries">Preliminaries<a class="anchor-link" href="#Preliminaries"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Generate a test example:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="generate_sample_inputs" class="doc_header"><code>generate_sample_inputs</code><a href="https://github.com/davidcpage/mctc/tree/master/mctc/ctc_simple.py#L16" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>generate_sample_inputs</code>(<strong><code>T</code></strong>, <strong><code>N</code></strong>, <strong><code>L_min</code></strong>, <strong><code>L_max</code></strong>, <strong><code>device</code></strong>=<em><code>device(type='cuda')</code></em>)</p>
</blockquote>
<p>Args:
    T: number of time steps
    N: batch size
    L_min, L_max: bounds on target length</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">sample_inputs</span> <span class="o">=</span> <span class="n">stay_scores</span><span class="p">,</span> <span class="n">move_scores</span><span class="p">,</span> <span class="n">target_lengths</span> <span class="o">=</span> <span class="n">generate_sample_inputs</span><span class="p">(</span><span class="n">T</span><span class="o">=</span><span class="mi">800</span><span class="p">,</span> <span class="n">N</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">L_min</span><span class="o">=</span><span class="mi">330</span><span class="p">,</span> <span class="n">L_max</span><span class="o">=</span><span class="mi">500</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Loss-implementations">Loss implementations<a class="anchor-link" href="#Loss-implementations"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="1.-Basic-pytorch">1. Basic pytorch<a class="anchor-link" href="#1.-Basic-pytorch"> </a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Here's a straightforward implementation in pytorch in logspace.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="logZ_fwd" class="doc_header"><code>logZ_fwd</code><a href="__main__.py#L5" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>logZ_fwd</code>(<strong><code>stay_scores</code></strong>, <strong><code>move_scores</code></strong>, <strong><code>target_lengths</code></strong>, <strong><code>S</code></strong>=<em><code>semiring(zero=-1e+38, one=0.0, mul=&lt;built-in method add of type object at 0x7fe19553c340&gt;, sum=&lt;built-in method logsumexp of type object at 0x7fe19553c340&gt;)</code></em>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">res</span> <span class="o">=</span> <span class="n">logZ_fwd</span><span class="p">(</span><span class="o">*</span><span class="n">sample_inputs</span><span class="p">)</span>
<span class="n">res</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor([970.6453, 971.6895, 982.3431, 972.2327, 976.6527, 977.2905, 979.2094,
        979.4549, 984.2569, 977.5510, 969.8797, 981.0777, 982.6025, 981.8260,
        975.4854, 980.4288, 983.0338, 984.4608, 975.9901, 973.8077, 983.5836,
        984.6028, 981.6602, 980.5414, 976.8457, 980.7314, 966.9128, 968.4935,
        982.5735, 983.4719, 982.3672, 981.2139, 968.8883, 981.0426, 976.7378,
        976.1961, 979.2068, 981.1317, 977.9713, 961.0184, 971.9141, 969.5038,
        979.3978, 978.5461, 982.9652, 964.3593, 980.6489, 984.6378, 979.3281,
        984.9939, 978.5788, 961.8087, 972.8093, 980.8213, 970.1132, 981.3785,
        975.8100, 964.0969, 982.7523, 972.8085, 976.3800, 984.9760, 970.7934,
        982.0917], device=&#39;cuda:0&#39;, grad_fn=&lt;LogsumexpBackward&gt;)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#report(benchmark_fwd_bwd((lambda *x: logZ_fwd(*x).sum()), *sample_inputs))</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="2.-Pytorch-with-grad">2. Pytorch with grad<a class="anchor-link" href="#2.-Pytorch-with-grad"> </a></h3>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="dot" class="doc_header"><code>dot</code><a href="https://github.com/davidcpage/mctc/tree/master/mctc/ctc_simple.py#L63" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>dot</code>(<strong><code>x</code></strong>, <strong><code>y</code></strong>, <strong><code>S</code></strong>=<em><code>semiring(zero=-1e+38, one=0.0, mul=&lt;built-in method add of type object at 0x7fe19553c340&gt;, sum=&lt;built-in method logsumexp of type object at 0x7fe19553c340&gt;)</code></em>, <strong><code>dim</code></strong>=<em><code>-1</code></em>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="LogZ" class="doc_header"><code>class</code> <code>LogZ</code><a href="https://github.com/davidcpage/mctc/tree/master/mctc/ctc_simple.py#L66" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>LogZ</code>() :: <code>Function</code></p>
</blockquote>
<p>Records operation history and defines formulas for differentiating ops.</p>
<p>Every operation performed on :class:<code>Tensor</code> s creates a new function
object, that performs the computation, and records that it happened.
The history is retained in the form of a DAG of functions, with edges
denoting data dependencies (<code>input &lt;- output</code>). Then, when backward is
called, the graph is processed in the topological ordering, by calling
:func:<code>backward</code> methods of each :class:<code>Function</code> object, and passing
returned gradients on to next :class:<code>Function</code> s.</p>
<p>Normally, the only way users interact with functions is by creating
subclasses and defining new operations. This is a recommended way of
extending torch.autograd.</p>
<p>Examples::</p>

<pre><code>&gt;&gt;&gt; class Exp(Function):
&gt;&gt;&gt;
&gt;&gt;&gt;     @staticmethod
&gt;&gt;&gt;     def forward(ctx, i):
&gt;&gt;&gt;         result = i.exp()
&gt;&gt;&gt;         ctx.save_for_backward(result)
&gt;&gt;&gt;         return result
&gt;&gt;&gt;
&gt;&gt;&gt;     @staticmethod
&gt;&gt;&gt;     def backward(ctx, grad_output):
&gt;&gt;&gt;         result, = ctx.saved_tensors
&gt;&gt;&gt;         return grad_output * result
&gt;&gt;&gt;
&gt;&gt;&gt; #Use it by calling the apply method:
&gt;&gt;&gt; output = Exp.apply(input)</code></pre>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="logZ_py" class="doc_header"><code>logZ_py</code><a href="https://github.com/davidcpage/mctc/tree/master/mctc/ctc_simple.py#L92" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>logZ_py</code>(<strong><code>stay_scores</code></strong>, <strong><code>move_scores</code></strong>, <strong><code>target_lengths</code></strong>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">fwds</span><span class="p">,</span> <span class="n">bwds</span> <span class="o">=</span> <span class="n">compare_fwd_bwd</span><span class="p">(</span><span class="n">float64</span><span class="p">(</span><span class="n">mean</span><span class="p">(</span><span class="n">logZ_fwd</span><span class="p">)),</span> <span class="n">float64</span><span class="p">(</span><span class="n">mean</span><span class="p">(</span><span class="n">logZ_py</span><span class="p">)),</span> <span class="o">*</span><span class="n">sample_inputs</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>fwd diff: 0.00e+00
bwd diff: 5.82e-11
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="3.-Cupy">3. Cupy<a class="anchor-link" href="#3.-Cupy"> </a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>NB: we defined beta_move to have size (T, N, L) not the more natural (T, N, L - 1) above. We did this so that we can stack it with beta_stay.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%%</span><span class="k">writefile</span> cuda/ctc_simple.cu
__device__ __forceinline__ FLOAT max2(FLOAT a, FLOAT a1) {
    return a &gt; a1 ? a : a1; 
}

__device__ __forceinline__ FLOAT logsumexp2(FLOAT a, FLOAT a1) {
    FLOAT maxa = max2(a, a1); 
    return maxa + log(exp(a-maxa) + exp(a1-maxa));
}

__device__ __forceinline__ FLOAT add(FLOAT a, FLOAT b) {return a + b;}
__device__ __forceinline__ FLOAT mul(FLOAT a, FLOAT b) {return a * b;}

extern &quot;C&quot; __global__ void fwd_bwd_logspace(
    FLOAT* __restrict__ alpha, FLOAT* __restrict__ beta_T,
    FLOAT* __restrict__ beta_stay, FLOAT* __restrict__ beta_move, 
    const FLOAT* __restrict__ stay_scores, const FLOAT* __restrict__ move_scores,
    int T, int N, int L
) {
    int bx = blockIdx.x, tx = threadIdx.x;
    if (tx &gt;= L) return;
    extern __shared__ FLOAT smem[];
    if (blockIdx.y == 0) {
        FLOAT a = ZERO, a1 = ZERO;
        a = alpha[bx * L + tx];
        for (int t = 0; t &lt; T; t++) {
            FLOAT *buf = smem + (t % 2) * blockDim.x;
            buf[tx] = a; __syncthreads(); 
            if (tx &gt; 0) {a1 = MUL(move_scores[(t * N + bx) * (L - 1) + tx - 1], buf[tx - 1]);}
            a = SUM(MUL(stay_scores[(t * N + bx) * L + tx], a), a1);
            alpha[((t + 1) * N + bx) * L + tx] = a;
        }
    }
    else {
        FLOAT b = ZERO, b1 = ZERO;
        b = beta_T[bx * L + tx];
        for (int t = T; t &gt; 0; t--) {
            FLOAT *buf = smem + (t % 2) * blockDim.x;
            buf[tx] = b; __syncthreads();
            if (tx &lt; L - 1) {
                b1 = MUL(buf[tx + 1], move_scores[(((t - 1) * N + bx) * (L - 1)) + tx]);
                beta_move[((t - 1) * N + bx) * L + tx] = b1;
            }
            b = MUL(b, stay_scores[(((t - 1) * N + bx) * L) + tx]);
            beta_stay[((t - 1) * N + bx) * L + tx] = b;
            b = SUM(b, b1);
        }
    }
  }
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="logZ_cupy" class="doc_header"><code>logZ_cupy</code><a href="__main__.py#L17" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>logZ_cupy</code>(<strong><code>stay_scores</code></strong>, <strong><code>move_scores</code></strong>, <strong><code>target_lengths</code></strong>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">fwds</span><span class="p">,</span> <span class="n">bwds</span> <span class="o">=</span> <span class="n">compare_fwd_bwd</span><span class="p">(</span><span class="n">float64</span><span class="p">(</span><span class="n">mean</span><span class="p">(</span><span class="n">logZ_py</span><span class="p">)),</span> <span class="n">float64</span><span class="p">(</span><span class="n">mean</span><span class="p">(</span><span class="n">logZ_cupy</span><span class="p">)),</span> <span class="o">*</span><span class="n">sample_inputs</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>fwd diff: 0.00e+00
bwd diff: 1.27e-02
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">report</span><span class="p">(</span><span class="n">benchmark_fwd_bwd</span><span class="p">(</span><span class="n">mean</span><span class="p">(</span><span class="n">logZ_cupy</span><span class="p">),</span> <span class="o">*</span><span class="n">sample_inputs</span><span class="p">,</span> <span class="n">nloops</span><span class="o">=</span><span class="mi">100</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>fwd: 19.44ms (19.22-19.71ms)
bwd: 7.28ms (7.22-7.39ms)
tot: 26.72ms (26.45-27.00ms)
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

</div>
 

